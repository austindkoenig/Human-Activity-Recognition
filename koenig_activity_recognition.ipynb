{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "koenig-activity-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/austindkoenig/Human-Activity-Recognition/blob/master/koenig_activity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DTNcHWuZf9g",
        "colab_type": "text"
      },
      "source": [
        "# <center>Human Activity Recognition</center>\n",
        "\n",
        "<center>Austin Koenig</center>\n",
        "\n",
        "## Introduction\n",
        "\n",
        "### Data\n",
        "\n",
        "The object of this project is to create a classifier which can differentiate between 14 different human activities from data collected via a triaxial accelerometer mounted to the subjects' wrists.\n",
        "\n",
        "Following is the specifications of the device used to record the data:\n",
        "\n",
        "#### Accelerometer Specifications\n",
        "\n",
        "| Property | Description |\n",
        "| --- | --- |\n",
        "| Type | tri-axial accelerometer |\n",
        "| Measurement range | [- 1.5g; + 1.5g] |\n",
        "| Sensitivity | 6 bits per axis |\n",
        "| Output data rate | 32 Hz |\n",
        "| Location | attached to the right wrist of the user with:<br><ul><li>x axis: pointing toward the hand</li><li>y axis: pointing toward the left</li><li>z axis: perpendicular to the plane of the hand</li></ul> |\n",
        "\n",
        "These data come from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer).\n",
        "\n",
        "#### Brief Discussion on Possible Issues and Solutions\n",
        "\n",
        "Consider the following table containing some statistics on the data.\n",
        "\n",
        "| Activity Name | # Sequences | % Sequences | Min Seq Length | Max Seq Length |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| Brush_teeth | 12 | 0.014303 | 844 | 3199 |\n",
        "| Climb_stairs | 102 | 0.121573 | 166 | 3199 |\n",
        "| Comb_hair | 31 | 0.036949 | 166 | 3199 |\n",
        "| Descend_stairs | 42 | 0.05006 | 156 | 3199 |\n",
        "| Drink_glass | 100 | 0.11919 | 156 | 3199 |\n",
        "| Eat_meat | 5 | 0.005959 | 156 | 9318 |\n",
        "| Eat_soup | 3 | 0.003576 | 156 | 9318 |\n",
        "| Getup_bed | 101 | 0.120381 | 156 | 9318 |\n",
        "| Liedown_bed | 28 | 0.033373 | 156 | 9318 |\n",
        "| Pour_water | 100 | 0.11919 | 156 | 9318 |\n",
        "| Sitdown_chair | 100 | 0.11919 | 125 | 9318 |\n",
        "| Standup_chair | 102 | 0.121573 | 125 | 9318 |\n",
        "| Use_telephone | 13 | 0.015495 | 125 | 9318 |\n",
        "| Walk | 100 | 0.11919 | 125 | 9318 | \n",
        "\n",
        "Notice that some of the classes represent fewer than one percent of the entire dataset whereas others account for around ten percent. This is called class imbalance, which is certainly something to keep under consideration when creating models. \n",
        "\n",
        "Furthermore, there are fewer than 1,000 samples in the entire dataset, although the samples are rather large in shape. In cases with so many features and so few samples, our performance is certainly hindered.\n",
        "\n",
        "Proposed Solutions:\n",
        "0. Do nothing\n",
        "1. Test a variety of algorithms\n",
        "2. Use a resampling technique\n",
        "3. Generate synthetic samples\n",
        "4. Slices observation sequences to create more samples\n",
        "5. Omit underpopulated classes from study\n",
        "\n",
        "The first option is what we'll call the null solution.\n",
        "\n",
        "Solution 1 is the most obvious solution, and should be done in many cases to juxtapose model evaluations for the best results possible.\n",
        "\n",
        "Solution 2 is more difficult to judge because of two contradicting factors: oversampling from a small class size may lead to overfitting, whereas undersampling from a large class size might induce a loss of signal that the model would otherwise learn. It would take more study to figure out how to optimally resample.\n",
        "\n",
        "Solution 3 is similar to solution 2 for the same reasons described.\n",
        "\n",
        "Solution 4 is also unknown. We may run into problems similar to those discussed with solutions 2 and 3. However, as most of the activities are cyclic in nature (that is, the activity appears similar over any two similarly-sized time intervals), we may be able to utilize this solution. For example, if we consider recording this data of a subject walking for 30 seconds, the subject might be moving between seconds 5 and 7 in a similar fashion as she might between seconds 22 and 24. In this sense, walking is cyclic: after two steps, it is the same movements over and over again. Eating is also cyclic, as is brushing teeth and descending stairs. \n",
        "\n",
        "A subset of the samples are extraordinarily long, some containing close to 10,000 time steps, which translates to about five minutes recording at 32 Hz. It is easy to convince oneself that splitting an extremely long sequence into smaller sequences to be used as individual observations might behoove our results without eliminating important long-term feature relationships. On the other hand, not all of our classes share this property of cyclicity: actions like pouring water, sitting down into a chair, and getting out of bed are not cyclic. Therefore, we might anticipate a shift in performance from non-cyclic activities to cyclic activities if we exercise this solution because cyclic activities will gain more samples.\n",
        "\n",
        "Finally, solution 5 is the easy way out. It is not detrimental to the project since only half of our classes are underpopulated. It is, indeed, a viable solution.\n",
        "\n",
        "-----\n",
        "\n",
        "### Preprocessing\n",
        "\n",
        "-----\n",
        "\n",
        "### Models\n",
        "\n",
        "-----\n",
        "\n",
        "### Metrics\n",
        "\n",
        "This section describes the metrics used in this project. Let $N_{tp}$, $N_{tn}$, $N_{fp}$, and $N_{fn}$ represent the numbers of true positives, true negatives, false positives, and false negatives, respectively. Finally, let $N$ represent the total number of observations tested (i.e. $N=N_{tp}+N_{tn}+N_{fp}+N_{fn}$).\n",
        "\n",
        "The metrics that will be examined are:\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1 Score\n",
        "- Confusion Matrix\n",
        "\n",
        "Accuracy, $A$, is defined as follows:\n",
        "\n",
        "$$A = \\frac{N_{tp} + N_{tn}}{N}$$\n",
        "\n",
        "Accuracy is a simple measure of the ratio of test observations for which the model made a correct positive classification to the total number of observations.\n",
        "\n",
        "Precision, $P$, is defined as follows:\n",
        "\n",
        "$$P = \\frac{N_{tp}}{N_{tp}+N_{fp}}$$\n",
        "\n",
        "Precision measures the ratio of correct positive classifications to the total number of positive classifications. It is different than accuracy because it can help differentiate between a naively-successful model and a truly-successful model. There's a frequently used example of predicting weather in a city where it is sunny 300 days out of the year. A naively-successful model might predict that everyday will be sunny, resulting in a 82% accuracy rate. While this rate is rather high, it is due to the nature of the data as opposed to the correctness of the model.\n",
        "\n",
        "Recall, $R$, is defined as follows:\n",
        "\n",
        "$$R = \\frac{N_{tp}}{N_{tp}+N_{fn}}$$\n",
        "\n",
        "The F1 Score, $F1$, is defined as follows:\n",
        "\n",
        "$$F1 = 2\\frac{PR}{P+R} = \\frac{2N_{tp}}{2N_{tp}+N_{fp}+N_{fn}}$$\n",
        "\n",
        "The F1 score is a sort of conglomerate value based on precision and recall.\n",
        "\n",
        "A confusion matrix is essentially a table of predictions and actual values. It helps to articulate the different types of misclassifications.\n",
        "\n",
        "-----\n",
        "\n",
        "## Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rr9GHRDzWKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-JcBJ-CzVe9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "-----\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "-----\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "These data come from [this repository](https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtikCxVOzAaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsE7tV5CZVY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}